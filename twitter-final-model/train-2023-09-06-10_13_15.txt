100
1674
0it [00:00, ?it/s]##mask_batch_T shape is : torch.Size([32, 32])
##mask_batch_TT shape is : torch.Size([32, 32, 32])
E_T_T.shapetorch.Size([32, 1024, 200]),E_T_V.shapetorch.Size([32, 1568, 200]),E_V_V.shapetorch.Size([32, 1568, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 32])
adj matrix shape is :@@## torch.Size([32, 81, 81])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 81, 1])
output的shape是: torch.Size([32, 81, 200])
##mask_batch_T shape is : torch.Size([32, 32])
##mask_batch_TT shape is : torch.Size([32, 32, 32])
E_T_T.shapetorch.Size([32, 1024, 200]),E_T_V.shapetorch.Size([32, 1568, 200]),E_V_V.shapetorch.Size([32, 1568, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 32])
adj matrix shape is :@@## torch.Size([32, 81, 81])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 81, 1])
output的shape是: torch.Size([32, 81, 200])
##mask_batch_T shape is : torch.Size([32, 32])
##mask_batch_TT shape is : torch.Size([32, 32, 32])
E_T_T.shapetorch.Size([32, 1024, 200]),E_T_V.shapetorch.Size([32, 1568, 200]),E_V_V.shapetorch.Size([32, 1568, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 32])
1it [00:01,  1.48s/it]##mask_batch_T shape is : torch.Size([32, 28])
##mask_batch_TT shape is : torch.Size([32, 28, 28])
E_T_T.shapetorch.Size([32, 784, 200]),E_T_V.shapetorch.Size([32, 1372, 200]),E_V_V.shapetorch.Size([32, 1372, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 28])
adj matrix shape is :@@## torch.Size([32, 77, 77])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 77, 1])
output的shape是: torch.Size([32, 77, 200])
##mask_batch_T shape is : torch.Size([32, 28])
##mask_batch_TT shape is : torch.Size([32, 28, 28])
E_T_T.shapetorch.Size([32, 784, 200]),E_T_V.shapetorch.Size([32, 1372, 200]),E_V_V.shapetorch.Size([32, 1372, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 28])
adj matrix shape is :@@## torch.Size([32, 77, 77])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 77, 1])
output的shape是: torch.Size([32, 77, 200])
##mask_batch_T shape is : torch.Size([32, 28])
##mask_batch_TT shape is : torch.Size([32, 28, 28])
E_T_T.shapetorch.Size([32, 784, 200]),E_T_V.shapetorch.Size([32, 1372, 200]),E_V_V.shapetorch.Size([32, 1372, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 28])
2it [00:01,  1.13it/s]##mask_batch_T shape is : torch.Size([32, 28])
##mask_batch_TT shape is : torch.Size([32, 28, 28])
E_T_T.shapetorch.Size([32, 784, 200]),E_T_V.shapetorch.Size([32, 1372, 200]),E_V_V.shapetorch.Size([32, 1372, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 28])
adj matrix shape is :@@## torch.Size([32, 77, 77])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 77, 1])
output的shape是: torch.Size([32, 77, 200])
##mask_batch_T shape is : torch.Size([32, 28])
##mask_batch_TT shape is : torch.Size([32, 28, 28])
E_T_T.shapetorch.Size([32, 784, 200]),E_T_V.shapetorch.Size([32, 1372, 200]),E_V_V.shapetorch.Size([32, 1372, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 28])
adj matrix shape is :@@## torch.Size([32, 77, 77])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 77, 1])
output的shape是: torch.Size([32, 77, 200])
##mask_batch_T shape is : torch.Size([32, 28])
##mask_batch_TT shape is : torch.Size([32, 28, 28])
E_T_T.shapetorch.Size([32, 784, 200]),E_T_V.shapetorch.Size([32, 1372, 200]),E_V_V.shapetorch.Size([32, 1372, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 28])
3it [00:02,  1.45it/s]3it [00:02,  1.20it/s]
0 0 32 64
/root/code/LogicMD/utils/data_utils.py:223: RuntimeWarning: invalid value encountered in scalar divide
  r_non_sarcasm = confusion[0][0] / (confusion[0][0] + confusion[0][1])
Train Epoch 0: Time 2.8111, Acc: 0.6667, Loss: 2.1152, Rumor_R: 0.6667, Rumor_P: 1.0000, Rumor_F: 0.8000, Non_Rumor_R: 0.0000, Non_Rumor_P: 0.0000, Non_Rumor_F1: 0.0000
0it [00:00, ?it/s]##mask_batch_T shape is : torch.Size([32, 23])
##mask_batch_TT shape is : torch.Size([32, 23, 23])
E_T_T.shapetorch.Size([32, 529, 200]),E_T_V.shapetorch.Size([32, 1127, 200]),E_V_V.shapetorch.Size([32, 1127, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 23])
adj matrix shape is :@@## torch.Size([32, 72, 72])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 72, 1])
output的shape是: torch.Size([32, 72, 200])
##mask_batch_T shape is : torch.Size([32, 23])
##mask_batch_TT shape is : torch.Size([32, 23, 23])
E_T_T.shapetorch.Size([32, 529, 200]),E_T_V.shapetorch.Size([32, 1127, 200]),E_V_V.shapetorch.Size([32, 1127, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 23])
adj matrix shape is :@@## torch.Size([32, 72, 72])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 72, 1])
output的shape是: torch.Size([32, 72, 200])
##mask_batch_T shape is : torch.Size([32, 23])
##mask_batch_TT shape is : torch.Size([32, 23, 23])
E_T_T.shapetorch.Size([32, 529, 200]),E_T_V.shapetorch.Size([32, 1127, 200]),E_V_V.shapetorch.Size([32, 1127, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 23])
1it [00:00,  2.92it/s]##mask_batch_T shape is : torch.Size([32, 22])
##mask_batch_TT shape is : torch.Size([32, 22, 22])
E_T_T.shapetorch.Size([32, 484, 200]),E_T_V.shapetorch.Size([32, 1078, 200]),E_V_V.shapetorch.Size([32, 1078, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 22])
adj matrix shape is :@@## torch.Size([32, 71, 71])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 71, 1])
output的shape是: torch.Size([32, 71, 200])
##mask_batch_T shape is : torch.Size([32, 22])
##mask_batch_TT shape is : torch.Size([32, 22, 22])
E_T_T.shapetorch.Size([32, 484, 200]),E_T_V.shapetorch.Size([32, 1078, 200]),E_V_V.shapetorch.Size([32, 1078, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 22])
adj matrix shape is :@@## torch.Size([32, 71, 71])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 71, 1])
output的shape是: torch.Size([32, 71, 200])
##mask_batch_T shape is : torch.Size([32, 22])
##mask_batch_TT shape is : torch.Size([32, 22, 22])
E_T_T.shapetorch.Size([32, 484, 200]),E_T_V.shapetorch.Size([32, 1078, 200]),E_V_V.shapetorch.Size([32, 1078, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 22])
2it [00:00,  3.33it/s]##mask_batch_T shape is : torch.Size([32, 24])
##mask_batch_TT shape is : torch.Size([32, 24, 24])
E_T_T.shapetorch.Size([32, 576, 200]),E_T_V.shapetorch.Size([32, 1176, 200]),E_V_V.shapetorch.Size([32, 1176, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 24])
adj matrix shape is :@@## torch.Size([32, 73, 73])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 73, 1])
output的shape是: torch.Size([32, 73, 200])
##mask_batch_T shape is : torch.Size([32, 24])
##mask_batch_TT shape is : torch.Size([32, 24, 24])
E_T_T.shapetorch.Size([32, 576, 200]),E_T_V.shapetorch.Size([32, 1176, 200]),E_V_V.shapetorch.Size([32, 1176, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 24])
adj matrix shape is :@@## torch.Size([32, 73, 73])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 73, 1])
output的shape是: torch.Size([32, 73, 200])
##mask_batch_T shape is : torch.Size([32, 24])
##mask_batch_TT shape is : torch.Size([32, 24, 24])
E_T_T.shapetorch.Size([32, 576, 200]),E_T_V.shapetorch.Size([32, 1176, 200]),E_V_V.shapetorch.Size([32, 1176, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 24])
3it [00:00,  3.48it/s]##mask_batch_T shape is : torch.Size([32, 26])
##mask_batch_TT shape is : torch.Size([32, 26, 26])
E_T_T.shapetorch.Size([32, 676, 200]),E_T_V.shapetorch.Size([32, 1274, 200]),E_V_V.shapetorch.Size([32, 1274, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 26])
adj matrix shape is :@@## torch.Size([32, 75, 75])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 75, 1])
output的shape是: torch.Size([32, 75, 200])
##mask_batch_T shape is : torch.Size([32, 26])
##mask_batch_TT shape is : torch.Size([32, 26, 26])
E_T_T.shapetorch.Size([32, 676, 200]),E_T_V.shapetorch.Size([32, 1274, 200]),E_V_V.shapetorch.Size([32, 1274, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 26])
adj matrix shape is :@@## torch.Size([32, 75, 75])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 75, 1])
output的shape是: torch.Size([32, 75, 200])
##mask_batch_T shape is : torch.Size([32, 26])
##mask_batch_TT shape is : torch.Size([32, 26, 26])
E_T_T.shapetorch.Size([32, 676, 200]),E_T_V.shapetorch.Size([32, 1274, 200]),E_V_V.shapetorch.Size([32, 1274, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 26])
4it [00:01,  3.53it/s]##mask_batch_T shape is : torch.Size([32, 27])
##mask_batch_TT shape is : torch.Size([32, 27, 27])
E_T_T.shapetorch.Size([32, 729, 200]),E_T_V.shapetorch.Size([32, 1323, 200]),E_V_V.shapetorch.Size([32, 1323, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 27])
adj matrix shape is :@@## torch.Size([32, 76, 76])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 76, 1])
output的shape是: torch.Size([32, 76, 200])
##mask_batch_T shape is : torch.Size([32, 27])
##mask_batch_TT shape is : torch.Size([32, 27, 27])
E_T_T.shapetorch.Size([32, 729, 200]),E_T_V.shapetorch.Size([32, 1323, 200]),E_V_V.shapetorch.Size([32, 1323, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 27])
adj matrix shape is :@@## torch.Size([32, 76, 76])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 76, 1])
output的shape是: torch.Size([32, 76, 200])
##mask_batch_T shape is : torch.Size([32, 27])
##mask_batch_TT shape is : torch.Size([32, 27, 27])
E_T_T.shapetorch.Size([32, 729, 200]),E_T_V.shapetorch.Size([32, 1323, 200]),E_V_V.shapetorch.Size([32, 1323, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 27])
5it [00:01,  3.51it/s]##mask_batch_T shape is : torch.Size([32, 27])
##mask_batch_TT shape is : torch.Size([32, 27, 27])
E_T_T.shapetorch.Size([32, 729, 200]),E_T_V.shapetorch.Size([32, 1323, 200]),E_V_V.shapetorch.Size([32, 1323, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 27])
adj matrix shape is :@@## torch.Size([32, 76, 76])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 76, 1])
output的shape是: torch.Size([32, 76, 200])
##mask_batch_T shape is : torch.Size([32, 27])
##mask_batch_TT shape is : torch.Size([32, 27, 27])
E_T_T.shapetorch.Size([32, 729, 200]),E_T_V.shapetorch.Size([32, 1323, 200]),E_V_V.shapetorch.Size([32, 1323, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 27])
adj matrix shape is :@@## torch.Size([32, 76, 76])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 76, 1])
output的shape是: torch.Size([32, 76, 200])
##mask_batch_T shape is : torch.Size([32, 27])
##mask_batch_TT shape is : torch.Size([32, 27, 27])
E_T_T.shapetorch.Size([32, 729, 200]),E_T_V.shapetorch.Size([32, 1323, 200]),E_V_V.shapetorch.Size([32, 1323, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 27])
6it [00:01,  3.54it/s]##mask_batch_T shape is : torch.Size([32, 21])
##mask_batch_TT shape is : torch.Size([32, 21, 21])
E_T_T.shapetorch.Size([32, 441, 200]),E_T_V.shapetorch.Size([32, 1029, 200]),E_V_V.shapetorch.Size([32, 1029, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 21])
adj matrix shape is :@@## torch.Size([32, 70, 70])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 70, 1])
output的shape是: torch.Size([32, 70, 200])
##mask_batch_T shape is : torch.Size([32, 21])
##mask_batch_TT shape is : torch.Size([32, 21, 21])
E_T_T.shapetorch.Size([32, 441, 200]),E_T_V.shapetorch.Size([32, 1029, 200]),E_V_V.shapetorch.Size([32, 1029, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 21])
adj matrix shape is :@@## torch.Size([32, 70, 70])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 70, 1])
output的shape是: torch.Size([32, 70, 200])
##mask_batch_T shape is : torch.Size([32, 21])
##mask_batch_TT shape is : torch.Size([32, 21, 21])
E_T_T.shapetorch.Size([32, 441, 200]),E_T_V.shapetorch.Size([32, 1029, 200]),E_V_V.shapetorch.Size([32, 1029, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 21])
7it [00:02,  3.56it/s]##mask_batch_T shape is : torch.Size([32, 19])
##mask_batch_TT shape is : torch.Size([32, 19, 19])
E_T_T.shapetorch.Size([32, 361, 200]),E_T_V.shapetorch.Size([32, 931, 200]),E_V_V.shapetorch.Size([32, 931, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 19])
adj matrix shape is :@@## torch.Size([32, 68, 68])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 68, 1])
output的shape是: torch.Size([32, 68, 200])
##mask_batch_T shape is : torch.Size([32, 19])
##mask_batch_TT shape is : torch.Size([32, 19, 19])
E_T_T.shapetorch.Size([32, 361, 200]),E_T_V.shapetorch.Size([32, 931, 200]),E_V_V.shapetorch.Size([32, 931, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 19])
adj matrix shape is :@@## torch.Size([32, 68, 68])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 68, 1])
output的shape是: torch.Size([32, 68, 200])
##mask_batch_T shape is : torch.Size([32, 19])
##mask_batch_TT shape is : torch.Size([32, 19, 19])
E_T_T.shapetorch.Size([32, 361, 200]),E_T_V.shapetorch.Size([32, 931, 200]),E_V_V.shapetorch.Size([32, 931, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 19])
8it [00:02,  3.64it/s]##mask_batch_T shape is : torch.Size([32, 25])
##mask_batch_TT shape is : torch.Size([32, 25, 25])
E_T_T.shapetorch.Size([32, 625, 200]),E_T_V.shapetorch.Size([32, 1225, 200]),E_V_V.shapetorch.Size([32, 1225, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 25])
adj matrix shape is :@@## torch.Size([32, 74, 74])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 74, 1])
output的shape是: torch.Size([32, 74, 200])
##mask_batch_T shape is : torch.Size([32, 25])
##mask_batch_TT shape is : torch.Size([32, 25, 25])
E_T_T.shapetorch.Size([32, 625, 200]),E_T_V.shapetorch.Size([32, 1225, 200]),E_V_V.shapetorch.Size([32, 1225, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 25])
adj matrix shape is :@@## torch.Size([32, 74, 74])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 74, 1])
output的shape是: torch.Size([32, 74, 200])
##mask_batch_T shape is : torch.Size([32, 25])
##mask_batch_TT shape is : torch.Size([32, 25, 25])
E_T_T.shapetorch.Size([32, 625, 200]),E_T_V.shapetorch.Size([32, 1225, 200]),E_V_V.shapetorch.Size([32, 1225, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 25])
9it [00:02,  3.59it/s]##mask_batch_T shape is : torch.Size([32, 25])
##mask_batch_TT shape is : torch.Size([32, 25, 25])
E_T_T.shapetorch.Size([32, 625, 200]),E_T_V.shapetorch.Size([32, 1225, 200]),E_V_V.shapetorch.Size([32, 1225, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 25])
adj matrix shape is :@@## torch.Size([32, 74, 74])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 74, 1])
output的shape是: torch.Size([32, 74, 200])
##mask_batch_T shape is : torch.Size([32, 25])
##mask_batch_TT shape is : torch.Size([32, 25, 25])
E_T_T.shapetorch.Size([32, 625, 200]),E_T_V.shapetorch.Size([32, 1225, 200]),E_V_V.shapetorch.Size([32, 1225, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 25])
adj matrix shape is :@@## torch.Size([32, 74, 74])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 74, 1])
output的shape是: torch.Size([32, 74, 200])
##mask_batch_T shape is : torch.Size([32, 25])
##mask_batch_TT shape is : torch.Size([32, 25, 25])
E_T_T.shapetorch.Size([32, 625, 200]),E_T_V.shapetorch.Size([32, 1225, 200]),E_V_V.shapetorch.Size([32, 1225, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 25])
10it [00:02,  3.59it/s]##mask_batch_T shape is : torch.Size([32, 29])
##mask_batch_TT shape is : torch.Size([32, 29, 29])
E_T_T.shapetorch.Size([32, 841, 200]),E_T_V.shapetorch.Size([32, 1421, 200]),E_V_V.shapetorch.Size([32, 1421, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 29])
adj matrix shape is :@@## torch.Size([32, 78, 78])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 78, 1])
output的shape是: torch.Size([32, 78, 200])
##mask_batch_T shape is : torch.Size([32, 29])
##mask_batch_TT shape is : torch.Size([32, 29, 29])
E_T_T.shapetorch.Size([32, 841, 200]),E_T_V.shapetorch.Size([32, 1421, 200]),E_V_V.shapetorch.Size([32, 1421, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 29])
adj matrix shape is :@@## torch.Size([32, 78, 78])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 78, 1])
output的shape是: torch.Size([32, 78, 200])
##mask_batch_T shape is : torch.Size([32, 29])
##mask_batch_TT shape is : torch.Size([32, 29, 29])
E_T_T.shapetorch.Size([32, 841, 200]),E_T_V.shapetorch.Size([32, 1421, 200]),E_V_V.shapetorch.Size([32, 1421, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 29])
11it [00:03,  3.57it/s]##mask_batch_T shape is : torch.Size([32, 25])
##mask_batch_TT shape is : torch.Size([32, 25, 25])
E_T_T.shapetorch.Size([32, 625, 200]),E_T_V.shapetorch.Size([32, 1225, 200]),E_V_V.shapetorch.Size([32, 1225, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 25])
adj matrix shape is :@@## torch.Size([32, 74, 74])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 74, 1])
output的shape是: torch.Size([32, 74, 200])
##mask_batch_T shape is : torch.Size([32, 25])
##mask_batch_TT shape is : torch.Size([32, 25, 25])
E_T_T.shapetorch.Size([32, 625, 200]),E_T_V.shapetorch.Size([32, 1225, 200]),E_V_V.shapetorch.Size([32, 1225, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 25])
adj matrix shape is :@@## torch.Size([32, 74, 74])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 74, 1])
output的shape是: torch.Size([32, 74, 200])
##mask_batch_T shape is : torch.Size([32, 25])
##mask_batch_TT shape is : torch.Size([32, 25, 25])
E_T_T.shapetorch.Size([32, 625, 200]),E_T_V.shapetorch.Size([32, 1225, 200]),E_V_V.shapetorch.Size([32, 1225, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 25])
12it [00:03,  3.59it/s]##mask_batch_T shape is : torch.Size([32, 29])
##mask_batch_TT shape is : torch.Size([32, 29, 29])
E_T_T.shapetorch.Size([32, 841, 200]),E_T_V.shapetorch.Size([32, 1421, 200]),E_V_V.shapetorch.Size([32, 1421, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 29])
adj matrix shape is :@@## torch.Size([32, 78, 78])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 78, 1])
output的shape是: torch.Size([32, 78, 200])
##mask_batch_T shape is : torch.Size([32, 29])
##mask_batch_TT shape is : torch.Size([32, 29, 29])
E_T_T.shapetorch.Size([32, 841, 200]),E_T_V.shapetorch.Size([32, 1421, 200]),E_V_V.shapetorch.Size([32, 1421, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 29])
adj matrix shape is :@@## torch.Size([32, 78, 78])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 78, 1])
output的shape是: torch.Size([32, 78, 200])
##mask_batch_T shape is : torch.Size([32, 29])
##mask_batch_TT shape is : torch.Size([32, 29, 29])
E_T_T.shapetorch.Size([32, 841, 200]),E_T_V.shapetorch.Size([32, 1421, 200]),E_V_V.shapetorch.Size([32, 1421, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 29])
13it [00:03,  3.52it/s]##mask_batch_T shape is : torch.Size([32, 25])
##mask_batch_TT shape is : torch.Size([32, 25, 25])
E_T_T.shapetorch.Size([32, 625, 200]),E_T_V.shapetorch.Size([32, 1225, 200]),E_V_V.shapetorch.Size([32, 1225, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 25])
adj matrix shape is :@@## torch.Size([32, 74, 74])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 74, 1])
output的shape是: torch.Size([32, 74, 200])
##mask_batch_T shape is : torch.Size([32, 25])
##mask_batch_TT shape is : torch.Size([32, 25, 25])
E_T_T.shapetorch.Size([32, 625, 200]),E_T_V.shapetorch.Size([32, 1225, 200]),E_V_V.shapetorch.Size([32, 1225, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 25])
adj matrix shape is :@@## torch.Size([32, 74, 74])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 74, 1])
output的shape是: torch.Size([32, 74, 200])
##mask_batch_T shape is : torch.Size([32, 25])
##mask_batch_TT shape is : torch.Size([32, 25, 25])
E_T_T.shapetorch.Size([32, 625, 200]),E_T_V.shapetorch.Size([32, 1225, 200]),E_V_V.shapetorch.Size([32, 1225, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 25])
14it [00:03,  3.56it/s]##mask_batch_T shape is : torch.Size([32, 25])
##mask_batch_TT shape is : torch.Size([32, 25, 25])
E_T_T.shapetorch.Size([32, 625, 200]),E_T_V.shapetorch.Size([32, 1225, 200]),E_V_V.shapetorch.Size([32, 1225, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 25])
adj matrix shape is :@@## torch.Size([32, 74, 74])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 74, 1])
output的shape是: torch.Size([32, 74, 200])
##mask_batch_T shape is : torch.Size([32, 25])
##mask_batch_TT shape is : torch.Size([32, 25, 25])
E_T_T.shapetorch.Size([32, 625, 200]),E_T_V.shapetorch.Size([32, 1225, 200]),E_V_V.shapetorch.Size([32, 1225, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 25])
adj matrix shape is :@@## torch.Size([32, 74, 74])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 74, 1])
output的shape是: torch.Size([32, 74, 200])
##mask_batch_T shape is : torch.Size([32, 25])
##mask_batch_TT shape is : torch.Size([32, 25, 25])
E_T_T.shapetorch.Size([32, 625, 200]),E_T_V.shapetorch.Size([32, 1225, 200]),E_V_V.shapetorch.Size([32, 1225, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 25])
15it [00:04,  3.58it/s]##mask_batch_T shape is : torch.Size([32, 24])
##mask_batch_TT shape is : torch.Size([32, 24, 24])
E_T_T.shapetorch.Size([32, 576, 200]),E_T_V.shapetorch.Size([32, 1176, 200]),E_V_V.shapetorch.Size([32, 1176, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 24])
adj matrix shape is :@@## torch.Size([32, 73, 73])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 73, 1])
output的shape是: torch.Size([32, 73, 200])
##mask_batch_T shape is : torch.Size([32, 24])
##mask_batch_TT shape is : torch.Size([32, 24, 24])
E_T_T.shapetorch.Size([32, 576, 200]),E_T_V.shapetorch.Size([32, 1176, 200]),E_V_V.shapetorch.Size([32, 1176, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 24])
adj matrix shape is :@@## torch.Size([32, 73, 73])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 73, 1])
output的shape是: torch.Size([32, 73, 200])
##mask_batch_T shape is : torch.Size([32, 24])
##mask_batch_TT shape is : torch.Size([32, 24, 24])
E_T_T.shapetorch.Size([32, 576, 200]),E_T_V.shapetorch.Size([32, 1176, 200]),E_V_V.shapetorch.Size([32, 1176, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 24])
16it [00:04,  3.59it/s]##mask_batch_T shape is : torch.Size([32, 27])
##mask_batch_TT shape is : torch.Size([32, 27, 27])
E_T_T.shapetorch.Size([32, 729, 200]),E_T_V.shapetorch.Size([32, 1323, 200]),E_V_V.shapetorch.Size([32, 1323, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 27])
adj matrix shape is :@@## torch.Size([32, 76, 76])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 76, 1])
output的shape是: torch.Size([32, 76, 200])
##mask_batch_T shape is : torch.Size([32, 27])
##mask_batch_TT shape is : torch.Size([32, 27, 27])
E_T_T.shapetorch.Size([32, 729, 200]),E_T_V.shapetorch.Size([32, 1323, 200]),E_V_V.shapetorch.Size([32, 1323, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 27])
adj matrix shape is :@@## torch.Size([32, 76, 76])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 76, 1])
output的shape是: torch.Size([32, 76, 200])
##mask_batch_T shape is : torch.Size([32, 27])
##mask_batch_TT shape is : torch.Size([32, 27, 27])
E_T_T.shapetorch.Size([32, 729, 200]),E_T_V.shapetorch.Size([32, 1323, 200]),E_V_V.shapetorch.Size([32, 1323, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 27])
17it [00:04,  3.58it/s]##mask_batch_T shape is : torch.Size([32, 23])
##mask_batch_TT shape is : torch.Size([32, 23, 23])
E_T_T.shapetorch.Size([32, 529, 200]),E_T_V.shapetorch.Size([32, 1127, 200]),E_V_V.shapetorch.Size([32, 1127, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 23])
adj matrix shape is :@@## torch.Size([32, 72, 72])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 72, 1])
output的shape是: torch.Size([32, 72, 200])
##mask_batch_T shape is : torch.Size([32, 23])
##mask_batch_TT shape is : torch.Size([32, 23, 23])
E_T_T.shapetorch.Size([32, 529, 200]),E_T_V.shapetorch.Size([32, 1127, 200]),E_V_V.shapetorch.Size([32, 1127, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 23])
adj matrix shape is :@@## torch.Size([32, 72, 72])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 72, 1])
output的shape是: torch.Size([32, 72, 200])
##mask_batch_T shape is : torch.Size([32, 23])
##mask_batch_TT shape is : torch.Size([32, 23, 23])
E_T_T.shapetorch.Size([32, 529, 200]),E_T_V.shapetorch.Size([32, 1127, 200]),E_V_V.shapetorch.Size([32, 1127, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 23])
18it [00:05,  3.64it/s]##mask_batch_T shape is : torch.Size([32, 26])
##mask_batch_TT shape is : torch.Size([32, 26, 26])
E_T_T.shapetorch.Size([32, 676, 200]),E_T_V.shapetorch.Size([32, 1274, 200]),E_V_V.shapetorch.Size([32, 1274, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 26])
adj matrix shape is :@@## torch.Size([32, 75, 75])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 75, 1])
output的shape是: torch.Size([32, 75, 200])
##mask_batch_T shape is : torch.Size([32, 26])
##mask_batch_TT shape is : torch.Size([32, 26, 26])
E_T_T.shapetorch.Size([32, 676, 200]),E_T_V.shapetorch.Size([32, 1274, 200]),E_V_V.shapetorch.Size([32, 1274, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 26])
adj matrix shape is :@@## torch.Size([32, 75, 75])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 75, 1])
output的shape是: torch.Size([32, 75, 200])
##mask_batch_T shape is : torch.Size([32, 26])
##mask_batch_TT shape is : torch.Size([32, 26, 26])
E_T_T.shapetorch.Size([32, 676, 200]),E_T_V.shapetorch.Size([32, 1274, 200]),E_V_V.shapetorch.Size([32, 1274, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 26])
19it [00:05,  3.59it/s]##mask_batch_T shape is : torch.Size([32, 25])
##mask_batch_TT shape is : torch.Size([32, 25, 25])
E_T_T.shapetorch.Size([32, 625, 200]),E_T_V.shapetorch.Size([32, 1225, 200]),E_V_V.shapetorch.Size([32, 1225, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 25])
adj matrix shape is :@@## torch.Size([32, 74, 74])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 74, 1])
output的shape是: torch.Size([32, 74, 200])
##mask_batch_T shape is : torch.Size([32, 25])
##mask_batch_TT shape is : torch.Size([32, 25, 25])
E_T_T.shapetorch.Size([32, 625, 200]),E_T_V.shapetorch.Size([32, 1225, 200]),E_V_V.shapetorch.Size([32, 1225, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 25])
adj matrix shape is :@@## torch.Size([32, 74, 74])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 74, 1])
output的shape是: torch.Size([32, 74, 200])
##mask_batch_T shape is : torch.Size([32, 25])
##mask_batch_TT shape is : torch.Size([32, 25, 25])
E_T_T.shapetorch.Size([32, 625, 200]),E_T_V.shapetorch.Size([32, 1225, 200]),E_V_V.shapetorch.Size([32, 1225, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 25])
20it [00:05,  3.60it/s]##mask_batch_T shape is : torch.Size([32, 24])
##mask_batch_TT shape is : torch.Size([32, 24, 24])
E_T_T.shapetorch.Size([32, 576, 200]),E_T_V.shapetorch.Size([32, 1176, 200]),E_V_V.shapetorch.Size([32, 1176, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 24])
adj matrix shape is :@@## torch.Size([32, 73, 73])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 73, 1])
output的shape是: torch.Size([32, 73, 200])
##mask_batch_T shape is : torch.Size([32, 24])
##mask_batch_TT shape is : torch.Size([32, 24, 24])
E_T_T.shapetorch.Size([32, 576, 200]),E_T_V.shapetorch.Size([32, 1176, 200]),E_V_V.shapetorch.Size([32, 1176, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 24])
adj matrix shape is :@@## torch.Size([32, 73, 73])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 73, 1])
output的shape是: torch.Size([32, 73, 200])
##mask_batch_T shape is : torch.Size([32, 24])
##mask_batch_TT shape is : torch.Size([32, 24, 24])
E_T_T.shapetorch.Size([32, 576, 200]),E_T_V.shapetorch.Size([32, 1176, 200]),E_V_V.shapetorch.Size([32, 1176, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 24])
21it [00:05,  3.55it/s]##mask_batch_T shape is : torch.Size([32, 21])
##mask_batch_TT shape is : torch.Size([32, 21, 21])
E_T_T.shapetorch.Size([32, 441, 200]),E_T_V.shapetorch.Size([32, 1029, 200]),E_V_V.shapetorch.Size([32, 1029, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 21])
adj matrix shape is :@@## torch.Size([32, 70, 70])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 70, 1])
output的shape是: torch.Size([32, 70, 200])
##mask_batch_T shape is : torch.Size([32, 21])
##mask_batch_TT shape is : torch.Size([32, 21, 21])
E_T_T.shapetorch.Size([32, 441, 200]),E_T_V.shapetorch.Size([32, 1029, 200]),E_V_V.shapetorch.Size([32, 1029, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 21])
adj matrix shape is :@@## torch.Size([32, 70, 70])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 70, 1])
output的shape是: torch.Size([32, 70, 200])
##mask_batch_T shape is : torch.Size([32, 21])
##mask_batch_TT shape is : torch.Size([32, 21, 21])
E_T_T.shapetorch.Size([32, 441, 200]),E_T_V.shapetorch.Size([32, 1029, 200]),E_V_V.shapetorch.Size([32, 1029, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 21])
22it [00:06,  3.62it/s]##mask_batch_T shape is : torch.Size([32, 21])
##mask_batch_TT shape is : torch.Size([32, 21, 21])
E_T_T.shapetorch.Size([32, 441, 200]),E_T_V.shapetorch.Size([32, 1029, 200]),E_V_V.shapetorch.Size([32, 1029, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 21])
adj matrix shape is :@@## torch.Size([32, 70, 70])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 70, 1])
output的shape是: torch.Size([32, 70, 200])
##mask_batch_T shape is : torch.Size([32, 21])
##mask_batch_TT shape is : torch.Size([32, 21, 21])
E_T_T.shapetorch.Size([32, 441, 200]),E_T_V.shapetorch.Size([32, 1029, 200]),E_V_V.shapetorch.Size([32, 1029, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 21])
adj matrix shape is :@@## torch.Size([32, 70, 70])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 70, 1])
output的shape是: torch.Size([32, 70, 200])
##mask_batch_T shape is : torch.Size([32, 21])
##mask_batch_TT shape is : torch.Size([32, 21, 21])
E_T_T.shapetorch.Size([32, 441, 200]),E_T_V.shapetorch.Size([32, 1029, 200]),E_V_V.shapetorch.Size([32, 1029, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 21])
23it [00:06,  3.62it/s]##mask_batch_T shape is : torch.Size([32, 23])
##mask_batch_TT shape is : torch.Size([32, 23, 23])
E_T_T.shapetorch.Size([32, 529, 200]),E_T_V.shapetorch.Size([32, 1127, 200]),E_V_V.shapetorch.Size([32, 1127, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 23])
adj matrix shape is :@@## torch.Size([32, 72, 72])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 72, 1])
output的shape是: torch.Size([32, 72, 200])
##mask_batch_T shape is : torch.Size([32, 23])
##mask_batch_TT shape is : torch.Size([32, 23, 23])
E_T_T.shapetorch.Size([32, 529, 200]),E_T_V.shapetorch.Size([32, 1127, 200]),E_V_V.shapetorch.Size([32, 1127, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 23])
adj matrix shape is :@@## torch.Size([32, 72, 72])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 72, 1])
output的shape是: torch.Size([32, 72, 200])
##mask_batch_T shape is : torch.Size([32, 23])
##mask_batch_TT shape is : torch.Size([32, 23, 23])
E_T_T.shapetorch.Size([32, 529, 200]),E_T_V.shapetorch.Size([32, 1127, 200]),E_V_V.shapetorch.Size([32, 1127, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 23])
24it [00:06,  3.62it/s]##mask_batch_T shape is : torch.Size([32, 23])
##mask_batch_TT shape is : torch.Size([32, 23, 23])
E_T_T.shapetorch.Size([32, 529, 200]),E_T_V.shapetorch.Size([32, 1127, 200]),E_V_V.shapetorch.Size([32, 1127, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 23])
adj matrix shape is :@@## torch.Size([32, 72, 72])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 72, 1])
output的shape是: torch.Size([32, 72, 200])
##mask_batch_T shape is : torch.Size([32, 23])
##mask_batch_TT shape is : torch.Size([32, 23, 23])
E_T_T.shapetorch.Size([32, 529, 200]),E_T_V.shapetorch.Size([32, 1127, 200]),E_V_V.shapetorch.Size([32, 1127, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 23])
adj matrix shape is :@@## torch.Size([32, 72, 72])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 72, 1])
output的shape是: torch.Size([32, 72, 200])
##mask_batch_T shape is : torch.Size([32, 23])
##mask_batch_TT shape is : torch.Size([32, 23, 23])
E_T_T.shapetorch.Size([32, 529, 200]),E_T_V.shapetorch.Size([32, 1127, 200]),E_V_V.shapetorch.Size([32, 1127, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 23])
25it [00:07,  3.59it/s]##mask_batch_T shape is : torch.Size([32, 24])
##mask_batch_TT shape is : torch.Size([32, 24, 24])
E_T_T.shapetorch.Size([32, 576, 200]),E_T_V.shapetorch.Size([32, 1176, 200]),E_V_V.shapetorch.Size([32, 1176, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 24])
adj matrix shape is :@@## torch.Size([32, 73, 73])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 73, 1])
output的shape是: torch.Size([32, 73, 200])
##mask_batch_T shape is : torch.Size([32, 24])
##mask_batch_TT shape is : torch.Size([32, 24, 24])
E_T_T.shapetorch.Size([32, 576, 200]),E_T_V.shapetorch.Size([32, 1176, 200]),E_V_V.shapetorch.Size([32, 1176, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 24])
adj matrix shape is :@@## torch.Size([32, 73, 73])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 73, 1])
output的shape是: torch.Size([32, 73, 200])
##mask_batch_T shape is : torch.Size([32, 24])
##mask_batch_TT shape is : torch.Size([32, 24, 24])
E_T_T.shapetorch.Size([32, 576, 200]),E_T_V.shapetorch.Size([32, 1176, 200]),E_V_V.shapetorch.Size([32, 1176, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 24])
26it [00:07,  3.59it/s]##mask_batch_T shape is : torch.Size([32, 23])
##mask_batch_TT shape is : torch.Size([32, 23, 23])
E_T_T.shapetorch.Size([32, 529, 200]),E_T_V.shapetorch.Size([32, 1127, 200]),E_V_V.shapetorch.Size([32, 1127, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 23])
adj matrix shape is :@@## torch.Size([32, 72, 72])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 72, 1])
output的shape是: torch.Size([32, 72, 200])
##mask_batch_T shape is : torch.Size([32, 23])
##mask_batch_TT shape is : torch.Size([32, 23, 23])
E_T_T.shapetorch.Size([32, 529, 200]),E_T_V.shapetorch.Size([32, 1127, 200]),E_V_V.shapetorch.Size([32, 1127, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 23])
adj matrix shape is :@@## torch.Size([32, 72, 72])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 72, 1])
output的shape是: torch.Size([32, 72, 200])
##mask_batch_T shape is : torch.Size([32, 23])
##mask_batch_TT shape is : torch.Size([32, 23, 23])
E_T_T.shapetorch.Size([32, 529, 200]),E_T_V.shapetorch.Size([32, 1127, 200]),E_V_V.shapetorch.Size([32, 1127, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 23])
27it [00:07,  3.62it/s]##mask_batch_T shape is : torch.Size([32, 24])
##mask_batch_TT shape is : torch.Size([32, 24, 24])
E_T_T.shapetorch.Size([32, 576, 200]),E_T_V.shapetorch.Size([32, 1176, 200]),E_V_V.shapetorch.Size([32, 1176, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 24])
adj matrix shape is :@@## torch.Size([32, 73, 73])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 73, 1])
output的shape是: torch.Size([32, 73, 200])
##mask_batch_T shape is : torch.Size([32, 24])
##mask_batch_TT shape is : torch.Size([32, 24, 24])
E_T_T.shapetorch.Size([32, 576, 200]),E_T_V.shapetorch.Size([32, 1176, 200]),E_V_V.shapetorch.Size([32, 1176, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 24])
adj matrix shape is :@@## torch.Size([32, 73, 73])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 73, 1])
output的shape是: torch.Size([32, 73, 200])
##mask_batch_T shape is : torch.Size([32, 24])
##mask_batch_TT shape is : torch.Size([32, 24, 24])
E_T_T.shapetorch.Size([32, 576, 200]),E_T_V.shapetorch.Size([32, 1176, 200]),E_V_V.shapetorch.Size([32, 1176, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 24])
28it [00:07,  3.65it/s]##mask_batch_T shape is : torch.Size([32, 26])
##mask_batch_TT shape is : torch.Size([32, 26, 26])
E_T_T.shapetorch.Size([32, 676, 200]),E_T_V.shapetorch.Size([32, 1274, 200]),E_V_V.shapetorch.Size([32, 1274, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 26])
adj matrix shape is :@@## torch.Size([32, 75, 75])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 75, 1])
output的shape是: torch.Size([32, 75, 200])
##mask_batch_T shape is : torch.Size([32, 26])
##mask_batch_TT shape is : torch.Size([32, 26, 26])
E_T_T.shapetorch.Size([32, 676, 200]),E_T_V.shapetorch.Size([32, 1274, 200]),E_V_V.shapetorch.Size([32, 1274, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 26])
adj matrix shape is :@@## torch.Size([32, 75, 75])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 75, 1])
output的shape是: torch.Size([32, 75, 200])
##mask_batch_T shape is : torch.Size([32, 26])
##mask_batch_TT shape is : torch.Size([32, 26, 26])
E_T_T.shapetorch.Size([32, 676, 200]),E_T_V.shapetorch.Size([32, 1274, 200]),E_V_V.shapetorch.Size([32, 1274, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 26])
29it [00:08,  3.60it/s]##mask_batch_T shape is : torch.Size([32, 17])
##mask_batch_TT shape is : torch.Size([32, 17, 17])
E_T_T.shapetorch.Size([32, 289, 200]),E_T_V.shapetorch.Size([32, 833, 200]),E_V_V.shapetorch.Size([32, 833, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 17])
adj matrix shape is :@@## torch.Size([32, 66, 66])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 66, 1])
output的shape是: torch.Size([32, 66, 200])
##mask_batch_T shape is : torch.Size([32, 17])
##mask_batch_TT shape is : torch.Size([32, 17, 17])
E_T_T.shapetorch.Size([32, 289, 200]),E_T_V.shapetorch.Size([32, 833, 200]),E_V_V.shapetorch.Size([32, 833, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 17])
adj matrix shape is :@@## torch.Size([32, 66, 66])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 66, 1])
output的shape是: torch.Size([32, 66, 200])
##mask_batch_T shape is : torch.Size([32, 17])
##mask_batch_TT shape is : torch.Size([32, 17, 17])
E_T_T.shapetorch.Size([32, 289, 200]),E_T_V.shapetorch.Size([32, 833, 200]),E_V_V.shapetorch.Size([32, 833, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 17])
30it [00:08,  3.68it/s]##mask_batch_T shape is : torch.Size([32, 19])
##mask_batch_TT shape is : torch.Size([32, 19, 19])
E_T_T.shapetorch.Size([32, 361, 200]),E_T_V.shapetorch.Size([32, 931, 200]),E_V_V.shapetorch.Size([32, 931, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 19])
adj matrix shape is :@@## torch.Size([32, 68, 68])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 68, 1])
output的shape是: torch.Size([32, 68, 200])
##mask_batch_T shape is : torch.Size([32, 19])
##mask_batch_TT shape is : torch.Size([32, 19, 19])
E_T_T.shapetorch.Size([32, 361, 200]),E_T_V.shapetorch.Size([32, 931, 200]),E_V_V.shapetorch.Size([32, 931, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 19])
adj matrix shape is :@@## torch.Size([32, 68, 68])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 68, 1])
output的shape是: torch.Size([32, 68, 200])
##mask_batch_T shape is : torch.Size([32, 19])
##mask_batch_TT shape is : torch.Size([32, 19, 19])
E_T_T.shapetorch.Size([32, 361, 200]),E_T_V.shapetorch.Size([32, 931, 200]),E_V_V.shapetorch.Size([32, 931, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 19])
31it [00:08,  3.69it/s]##mask_batch_T shape is : torch.Size([32, 13])
##mask_batch_TT shape is : torch.Size([32, 13, 13])
E_T_T.shapetorch.Size([32, 169, 200]),E_T_V.shapetorch.Size([32, 637, 200]),E_V_V.shapetorch.Size([32, 637, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 13])
adj matrix shape is :@@## torch.Size([32, 62, 62])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 62, 1])
output的shape是: torch.Size([32, 62, 200])
##mask_batch_T shape is : torch.Size([32, 13])
##mask_batch_TT shape is : torch.Size([32, 13, 13])
E_T_T.shapetorch.Size([32, 169, 200]),E_T_V.shapetorch.Size([32, 637, 200]),E_V_V.shapetorch.Size([32, 637, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 13])
adj matrix shape is :@@## torch.Size([32, 62, 62])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 62, 1])
output的shape是: torch.Size([32, 62, 200])
##mask_batch_T shape is : torch.Size([32, 13])
##mask_batch_TT shape is : torch.Size([32, 13, 13])
E_T_T.shapetorch.Size([32, 169, 200]),E_T_V.shapetorch.Size([32, 637, 200]),E_V_V.shapetorch.Size([32, 637, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 13])
32it [00:08,  3.75it/s]##mask_batch_T shape is : torch.Size([32, 12])
##mask_batch_TT shape is : torch.Size([32, 12, 12])
E_T_T.shapetorch.Size([32, 144, 200]),E_T_V.shapetorch.Size([32, 588, 200]),E_V_V.shapetorch.Size([32, 588, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 12])
adj matrix shape is :@@## torch.Size([32, 61, 61])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 61, 1])
output的shape是: torch.Size([32, 61, 200])
##mask_batch_T shape is : torch.Size([32, 12])
##mask_batch_TT shape is : torch.Size([32, 12, 12])
E_T_T.shapetorch.Size([32, 144, 200]),E_T_V.shapetorch.Size([32, 588, 200]),E_V_V.shapetorch.Size([32, 588, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 12])
adj matrix shape is :@@## torch.Size([32, 61, 61])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 61, 1])
output的shape是: torch.Size([32, 61, 200])
##mask_batch_T shape is : torch.Size([32, 12])
##mask_batch_TT shape is : torch.Size([32, 12, 12])
E_T_T.shapetorch.Size([32, 144, 200]),E_T_V.shapetorch.Size([32, 588, 200]),E_V_V.shapetorch.Size([32, 588, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 12])
33it [00:09,  3.78it/s]##mask_batch_T shape is : torch.Size([32, 17])
##mask_batch_TT shape is : torch.Size([32, 17, 17])
E_T_T.shapetorch.Size([32, 289, 200]),E_T_V.shapetorch.Size([32, 833, 200]),E_V_V.shapetorch.Size([32, 833, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 17])
adj matrix shape is :@@## torch.Size([32, 66, 66])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 66, 1])
output的shape是: torch.Size([32, 66, 200])
##mask_batch_T shape is : torch.Size([32, 17])
##mask_batch_TT shape is : torch.Size([32, 17, 17])
E_T_T.shapetorch.Size([32, 289, 200]),E_T_V.shapetorch.Size([32, 833, 200]),E_V_V.shapetorch.Size([32, 833, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 17])
adj matrix shape is :@@## torch.Size([32, 66, 66])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 66, 1])
output的shape是: torch.Size([32, 66, 200])
##mask_batch_T shape is : torch.Size([32, 17])
##mask_batch_TT shape is : torch.Size([32, 17, 17])
E_T_T.shapetorch.Size([32, 289, 200]),E_T_V.shapetorch.Size([32, 833, 200]),E_V_V.shapetorch.Size([32, 833, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 17])
34it [00:09,  3.79it/s]##mask_batch_T shape is : torch.Size([32, 17])
##mask_batch_TT shape is : torch.Size([32, 17, 17])
E_T_T.shapetorch.Size([32, 289, 200]),E_T_V.shapetorch.Size([32, 833, 200]),E_V_V.shapetorch.Size([32, 833, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 17])
adj matrix shape is :@@## torch.Size([32, 66, 66])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 66, 1])
output的shape是: torch.Size([32, 66, 200])
##mask_batch_T shape is : torch.Size([32, 17])
##mask_batch_TT shape is : torch.Size([32, 17, 17])
E_T_T.shapetorch.Size([32, 289, 200]),E_T_V.shapetorch.Size([32, 833, 200]),E_V_V.shapetorch.Size([32, 833, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 17])
adj matrix shape is :@@## torch.Size([32, 66, 66])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 66, 1])
output的shape是: torch.Size([32, 66, 200])
##mask_batch_T shape is : torch.Size([32, 17])
##mask_batch_TT shape is : torch.Size([32, 17, 17])
E_T_T.shapetorch.Size([32, 289, 200]),E_T_V.shapetorch.Size([32, 833, 200]),E_V_V.shapetorch.Size([32, 833, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 17])
35it [00:09,  3.85it/s]##mask_batch_T shape is : torch.Size([32, 20])
##mask_batch_TT shape is : torch.Size([32, 20, 20])
E_T_T.shapetorch.Size([32, 400, 200]),E_T_V.shapetorch.Size([32, 980, 200]),E_V_V.shapetorch.Size([32, 980, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 20])
adj matrix shape is :@@## torch.Size([32, 69, 69])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 69, 1])
output的shape是: torch.Size([32, 69, 200])
##mask_batch_T shape is : torch.Size([32, 20])
##mask_batch_TT shape is : torch.Size([32, 20, 20])
E_T_T.shapetorch.Size([32, 400, 200]),E_T_V.shapetorch.Size([32, 980, 200]),E_V_V.shapetorch.Size([32, 980, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 20])
adj matrix shape is :@@## torch.Size([32, 69, 69])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 69, 1])
output的shape是: torch.Size([32, 69, 200])
##mask_batch_T shape is : torch.Size([32, 20])
##mask_batch_TT shape is : torch.Size([32, 20, 20])
E_T_T.shapetorch.Size([32, 400, 200]),E_T_V.shapetorch.Size([32, 980, 200]),E_V_V.shapetorch.Size([32, 980, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 20])
36it [00:09,  3.83it/s]##mask_batch_T shape is : torch.Size([32, 15])
##mask_batch_TT shape is : torch.Size([32, 15, 15])
E_T_T.shapetorch.Size([32, 225, 200]),E_T_V.shapetorch.Size([32, 735, 200]),E_V_V.shapetorch.Size([32, 735, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 15])
adj matrix shape is :@@## torch.Size([32, 64, 64])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 64, 1])
output的shape是: torch.Size([32, 64, 200])
##mask_batch_T shape is : torch.Size([32, 15])
##mask_batch_TT shape is : torch.Size([32, 15, 15])
E_T_T.shapetorch.Size([32, 225, 200]),E_T_V.shapetorch.Size([32, 735, 200]),E_V_V.shapetorch.Size([32, 735, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 15])
adj matrix shape is :@@## torch.Size([32, 64, 64])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 64, 1])
output的shape是: torch.Size([32, 64, 200])
##mask_batch_T shape is : torch.Size([32, 15])
##mask_batch_TT shape is : torch.Size([32, 15, 15])
E_T_T.shapetorch.Size([32, 225, 200]),E_T_V.shapetorch.Size([32, 735, 200]),E_V_V.shapetorch.Size([32, 735, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 15])
37it [00:10,  3.83it/s]##mask_batch_T shape is : torch.Size([32, 14])
##mask_batch_TT shape is : torch.Size([32, 14, 14])
E_T_T.shapetorch.Size([32, 196, 200]),E_T_V.shapetorch.Size([32, 686, 200]),E_V_V.shapetorch.Size([32, 686, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 14])
adj matrix shape is :@@## torch.Size([32, 63, 63])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 63, 1])
output的shape是: torch.Size([32, 63, 200])
##mask_batch_T shape is : torch.Size([32, 14])
##mask_batch_TT shape is : torch.Size([32, 14, 14])
E_T_T.shapetorch.Size([32, 196, 200]),E_T_V.shapetorch.Size([32, 686, 200]),E_V_V.shapetorch.Size([32, 686, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 14])
adj matrix shape is :@@## torch.Size([32, 63, 63])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 63, 1])
output的shape是: torch.Size([32, 63, 200])
##mask_batch_T shape is : torch.Size([32, 14])
##mask_batch_TT shape is : torch.Size([32, 14, 14])
E_T_T.shapetorch.Size([32, 196, 200]),E_T_V.shapetorch.Size([32, 686, 200]),E_V_V.shapetorch.Size([32, 686, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 14])
38it [00:10,  3.85it/s]##mask_batch_T shape is : torch.Size([32, 17])
##mask_batch_TT shape is : torch.Size([32, 17, 17])
E_T_T.shapetorch.Size([32, 289, 200]),E_T_V.shapetorch.Size([32, 833, 200]),E_V_V.shapetorch.Size([32, 833, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 17])
adj matrix shape is :@@## torch.Size([32, 66, 66])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 66, 1])
output的shape是: torch.Size([32, 66, 200])
##mask_batch_T shape is : torch.Size([32, 17])
##mask_batch_TT shape is : torch.Size([32, 17, 17])
E_T_T.shapetorch.Size([32, 289, 200]),E_T_V.shapetorch.Size([32, 833, 200]),E_V_V.shapetorch.Size([32, 833, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 17])
adj matrix shape is :@@## torch.Size([32, 66, 66])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 66, 1])
output的shape是: torch.Size([32, 66, 200])
##mask_batch_T shape is : torch.Size([32, 17])
##mask_batch_TT shape is : torch.Size([32, 17, 17])
E_T_T.shapetorch.Size([32, 289, 200]),E_T_V.shapetorch.Size([32, 833, 200]),E_V_V.shapetorch.Size([32, 833, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 17])
39it [00:10,  3.82it/s]##mask_batch_T shape is : torch.Size([32, 13])
##mask_batch_TT shape is : torch.Size([32, 13, 13])
E_T_T.shapetorch.Size([32, 169, 200]),E_T_V.shapetorch.Size([32, 637, 200]),E_V_V.shapetorch.Size([32, 637, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 13])
adj matrix shape is :@@## torch.Size([32, 62, 62])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 62, 1])
output的shape是: torch.Size([32, 62, 200])
##mask_batch_T shape is : torch.Size([32, 13])
##mask_batch_TT shape is : torch.Size([32, 13, 13])
E_T_T.shapetorch.Size([32, 169, 200]),E_T_V.shapetorch.Size([32, 637, 200]),E_V_V.shapetorch.Size([32, 637, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 13])
adj matrix shape is :@@## torch.Size([32, 62, 62])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 62, 1])
output的shape是: torch.Size([32, 62, 200])
##mask_batch_T shape is : torch.Size([32, 13])
##mask_batch_TT shape is : torch.Size([32, 13, 13])
E_T_T.shapetorch.Size([32, 169, 200]),E_T_V.shapetorch.Size([32, 637, 200]),E_V_V.shapetorch.Size([32, 637, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 13])
40it [00:10,  3.86it/s]##mask_batch_T shape is : torch.Size([32, 17])
##mask_batch_TT shape is : torch.Size([32, 17, 17])
E_T_T.shapetorch.Size([32, 289, 200]),E_T_V.shapetorch.Size([32, 833, 200]),E_V_V.shapetorch.Size([32, 833, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 17])
adj matrix shape is :@@## torch.Size([32, 66, 66])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 66, 1])
output的shape是: torch.Size([32, 66, 200])
##mask_batch_T shape is : torch.Size([32, 17])
##mask_batch_TT shape is : torch.Size([32, 17, 17])
E_T_T.shapetorch.Size([32, 289, 200]),E_T_V.shapetorch.Size([32, 833, 200]),E_V_V.shapetorch.Size([32, 833, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 17])
adj matrix shape is :@@## torch.Size([32, 66, 66])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 66, 1])
output的shape是: torch.Size([32, 66, 200])
##mask_batch_T shape is : torch.Size([32, 17])
##mask_batch_TT shape is : torch.Size([32, 17, 17])
E_T_T.shapetorch.Size([32, 289, 200]),E_T_V.shapetorch.Size([32, 833, 200]),E_V_V.shapetorch.Size([32, 833, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 17])
41it [00:11,  3.82it/s]##mask_batch_T shape is : torch.Size([32, 20])
##mask_batch_TT shape is : torch.Size([32, 20, 20])
E_T_T.shapetorch.Size([32, 400, 200]),E_T_V.shapetorch.Size([32, 980, 200]),E_V_V.shapetorch.Size([32, 980, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 20])
adj matrix shape is :@@## torch.Size([32, 69, 69])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 69, 1])
output的shape是: torch.Size([32, 69, 200])
##mask_batch_T shape is : torch.Size([32, 20])
##mask_batch_TT shape is : torch.Size([32, 20, 20])
E_T_T.shapetorch.Size([32, 400, 200]),E_T_V.shapetorch.Size([32, 980, 200]),E_V_V.shapetorch.Size([32, 980, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 20])
adj matrix shape is :@@## torch.Size([32, 69, 69])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 69, 1])
output的shape是: torch.Size([32, 69, 200])
##mask_batch_T shape is : torch.Size([32, 20])
##mask_batch_TT shape is : torch.Size([32, 20, 20])
E_T_T.shapetorch.Size([32, 400, 200]),E_T_V.shapetorch.Size([32, 980, 200]),E_V_V.shapetorch.Size([32, 980, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 20])
42it [00:11,  3.81it/s]##mask_batch_T shape is : torch.Size([32, 23])
##mask_batch_TT shape is : torch.Size([32, 23, 23])
E_T_T.shapetorch.Size([32, 529, 200]),E_T_V.shapetorch.Size([32, 1127, 200]),E_V_V.shapetorch.Size([32, 1127, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 23])
adj matrix shape is :@@## torch.Size([32, 72, 72])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 72, 1])
output的shape是: torch.Size([32, 72, 200])
##mask_batch_T shape is : torch.Size([32, 23])
##mask_batch_TT shape is : torch.Size([32, 23, 23])
E_T_T.shapetorch.Size([32, 529, 200]),E_T_V.shapetorch.Size([32, 1127, 200]),E_V_V.shapetorch.Size([32, 1127, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 23])
adj matrix shape is :@@## torch.Size([32, 72, 72])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 72, 1])
output的shape是: torch.Size([32, 72, 200])
##mask_batch_T shape is : torch.Size([32, 23])
##mask_batch_TT shape is : torch.Size([32, 23, 23])
E_T_T.shapetorch.Size([32, 529, 200]),E_T_V.shapetorch.Size([32, 1127, 200]),E_V_V.shapetorch.Size([32, 1127, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 23])
43it [00:11,  3.79it/s]##mask_batch_T shape is : torch.Size([32, 21])
##mask_batch_TT shape is : torch.Size([32, 21, 21])
E_T_T.shapetorch.Size([32, 441, 200]),E_T_V.shapetorch.Size([32, 1029, 200]),E_V_V.shapetorch.Size([32, 1029, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 21])
adj matrix shape is :@@## torch.Size([32, 70, 70])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 70, 1])
output的shape是: torch.Size([32, 70, 200])
##mask_batch_T shape is : torch.Size([32, 21])
##mask_batch_TT shape is : torch.Size([32, 21, 21])
E_T_T.shapetorch.Size([32, 441, 200]),E_T_V.shapetorch.Size([32, 1029, 200]),E_V_V.shapetorch.Size([32, 1029, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 21])
adj matrix shape is :@@## torch.Size([32, 70, 70])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 70, 1])
output的shape是: torch.Size([32, 70, 200])
##mask_batch_T shape is : torch.Size([32, 21])
##mask_batch_TT shape is : torch.Size([32, 21, 21])
E_T_T.shapetorch.Size([32, 441, 200]),E_T_V.shapetorch.Size([32, 1029, 200]),E_V_V.shapetorch.Size([32, 1029, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 21])
44it [00:12,  3.76it/s]##mask_batch_T shape is : torch.Size([32, 20])
##mask_batch_TT shape is : torch.Size([32, 20, 20])
E_T_T.shapetorch.Size([32, 400, 200]),E_T_V.shapetorch.Size([32, 980, 200]),E_V_V.shapetorch.Size([32, 980, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 20])
adj matrix shape is :@@## torch.Size([32, 69, 69])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 69, 1])
output的shape是: torch.Size([32, 69, 200])
##mask_batch_T shape is : torch.Size([32, 20])
##mask_batch_TT shape is : torch.Size([32, 20, 20])
E_T_T.shapetorch.Size([32, 400, 200]),E_T_V.shapetorch.Size([32, 980, 200]),E_V_V.shapetorch.Size([32, 980, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 20])
adj matrix shape is :@@## torch.Size([32, 69, 69])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 69, 1])
output的shape是: torch.Size([32, 69, 200])
##mask_batch_T shape is : torch.Size([32, 20])
##mask_batch_TT shape is : torch.Size([32, 20, 20])
E_T_T.shapetorch.Size([32, 400, 200]),E_T_V.shapetorch.Size([32, 980, 200]),E_V_V.shapetorch.Size([32, 980, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 20])
45it [00:12,  3.71it/s]##mask_batch_T shape is : torch.Size([32, 20])
##mask_batch_TT shape is : torch.Size([32, 20, 20])
E_T_T.shapetorch.Size([32, 400, 200]),E_T_V.shapetorch.Size([32, 980, 200]),E_V_V.shapetorch.Size([32, 980, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 20])
adj matrix shape is :@@## torch.Size([32, 69, 69])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 69, 1])
output的shape是: torch.Size([32, 69, 200])
##mask_batch_T shape is : torch.Size([32, 20])
##mask_batch_TT shape is : torch.Size([32, 20, 20])
E_T_T.shapetorch.Size([32, 400, 200]),E_T_V.shapetorch.Size([32, 980, 200]),E_V_V.shapetorch.Size([32, 980, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 20])
adj matrix shape is :@@## torch.Size([32, 69, 69])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 69, 1])
output的shape是: torch.Size([32, 69, 200])
##mask_batch_T shape is : torch.Size([32, 20])
##mask_batch_TT shape is : torch.Size([32, 20, 20])
E_T_T.shapetorch.Size([32, 400, 200]),E_T_V.shapetorch.Size([32, 980, 200]),E_V_V.shapetorch.Size([32, 980, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 20])
46it [00:12,  3.76it/s]##mask_batch_T shape is : torch.Size([32, 22])
##mask_batch_TT shape is : torch.Size([32, 22, 22])
E_T_T.shapetorch.Size([32, 484, 200]),E_T_V.shapetorch.Size([32, 1078, 200]),E_V_V.shapetorch.Size([32, 1078, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 22])
adj matrix shape is :@@## torch.Size([32, 71, 71])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 71, 1])
output的shape是: torch.Size([32, 71, 200])
##mask_batch_T shape is : torch.Size([32, 22])
##mask_batch_TT shape is : torch.Size([32, 22, 22])
E_T_T.shapetorch.Size([32, 484, 200]),E_T_V.shapetorch.Size([32, 1078, 200]),E_V_V.shapetorch.Size([32, 1078, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 22])
adj matrix shape is :@@## torch.Size([32, 71, 71])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 71, 1])
output的shape是: torch.Size([32, 71, 200])
##mask_batch_T shape is : torch.Size([32, 22])
##mask_batch_TT shape is : torch.Size([32, 22, 22])
E_T_T.shapetorch.Size([32, 484, 200]),E_T_V.shapetorch.Size([32, 1078, 200]),E_V_V.shapetorch.Size([32, 1078, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 22])
47it [00:12,  3.74it/s]##mask_batch_T shape is : torch.Size([32, 20])
##mask_batch_TT shape is : torch.Size([32, 20, 20])
E_T_T.shapetorch.Size([32, 400, 200]),E_T_V.shapetorch.Size([32, 980, 200]),E_V_V.shapetorch.Size([32, 980, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 20])
adj matrix shape is :@@## torch.Size([32, 69, 69])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 69, 1])
output的shape是: torch.Size([32, 69, 200])
##mask_batch_T shape is : torch.Size([32, 20])
##mask_batch_TT shape is : torch.Size([32, 20, 20])
E_T_T.shapetorch.Size([32, 400, 200]),E_T_V.shapetorch.Size([32, 980, 200]),E_V_V.shapetorch.Size([32, 980, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 20])
adj matrix shape is :@@## torch.Size([32, 69, 69])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 69, 1])
output的shape是: torch.Size([32, 69, 200])
##mask_batch_T shape is : torch.Size([32, 20])
##mask_batch_TT shape is : torch.Size([32, 20, 20])
E_T_T.shapetorch.Size([32, 400, 200]),E_T_V.shapetorch.Size([32, 980, 200]),E_V_V.shapetorch.Size([32, 980, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 20])
48it [00:13,  3.73it/s]##mask_batch_T shape is : torch.Size([32, 19])
##mask_batch_TT shape is : torch.Size([32, 19, 19])
E_T_T.shapetorch.Size([32, 361, 200]),E_T_V.shapetorch.Size([32, 931, 200]),E_V_V.shapetorch.Size([32, 931, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 19])
adj matrix shape is :@@## torch.Size([32, 68, 68])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 68, 1])
output的shape是: torch.Size([32, 68, 200])
##mask_batch_T shape is : torch.Size([32, 19])
##mask_batch_TT shape is : torch.Size([32, 19, 19])
E_T_T.shapetorch.Size([32, 361, 200]),E_T_V.shapetorch.Size([32, 931, 200]),E_V_V.shapetorch.Size([32, 931, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 19])
adj matrix shape is :@@## torch.Size([32, 68, 68])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 68, 1])
output的shape是: torch.Size([32, 68, 200])
##mask_batch_T shape is : torch.Size([32, 19])
##mask_batch_TT shape is : torch.Size([32, 19, 19])
E_T_T.shapetorch.Size([32, 361, 200]),E_T_V.shapetorch.Size([32, 931, 200]),E_V_V.shapetorch.Size([32, 931, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 19])
49it [00:13,  3.69it/s]##mask_batch_T shape is : torch.Size([32, 21])
##mask_batch_TT shape is : torch.Size([32, 21, 21])
E_T_T.shapetorch.Size([32, 441, 200]),E_T_V.shapetorch.Size([32, 1029, 200]),E_V_V.shapetorch.Size([32, 1029, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 21])
adj matrix shape is :@@## torch.Size([32, 70, 70])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 70, 1])
output的shape是: torch.Size([32, 70, 200])
##mask_batch_T shape is : torch.Size([32, 21])
##mask_batch_TT shape is : torch.Size([32, 21, 21])
E_T_T.shapetorch.Size([32, 441, 200]),E_T_V.shapetorch.Size([32, 1029, 200]),E_V_V.shapetorch.Size([32, 1029, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 21])
adj matrix shape is :@@## torch.Size([32, 70, 70])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 70, 1])
output的shape是: torch.Size([32, 70, 200])
##mask_batch_T shape is : torch.Size([32, 21])
##mask_batch_TT shape is : torch.Size([32, 21, 21])
E_T_T.shapetorch.Size([32, 441, 200]),E_T_V.shapetorch.Size([32, 1029, 200]),E_V_V.shapetorch.Size([32, 1029, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 21])
50it [00:13,  3.72it/s]##mask_batch_T shape is : torch.Size([32, 74])
##mask_batch_TT shape is : torch.Size([32, 74, 74])
E_T_T.shapetorch.Size([32, 5476, 200]),E_T_V.shapetorch.Size([32, 3626, 200]),E_V_V.shapetorch.Size([32, 3626, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 74])
adj matrix shape is :@@## torch.Size([32, 123, 123])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 123, 1])
output的shape是: torch.Size([32, 123, 200])
##mask_batch_T shape is : torch.Size([32, 74])
##mask_batch_TT shape is : torch.Size([32, 74, 74])
E_T_T.shapetorch.Size([32, 5476, 200]),E_T_V.shapetorch.Size([32, 3626, 200]),E_V_V.shapetorch.Size([32, 3626, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 74])
adj matrix shape is :@@## torch.Size([32, 123, 123])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 123, 1])
output的shape是: torch.Size([32, 123, 200])
##mask_batch_T shape is : torch.Size([32, 74])
##mask_batch_TT shape is : torch.Size([32, 74, 74])
E_T_T.shapetorch.Size([32, 5476, 200]),E_T_V.shapetorch.Size([32, 3626, 200]),E_V_V.shapetorch.Size([32, 3626, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 74])
51it [00:14,  3.19it/s]##mask_batch_T shape is : torch.Size([32, 49])
##mask_batch_TT shape is : torch.Size([32, 49, 49])
E_T_T.shapetorch.Size([32, 2401, 200]),E_T_V.shapetorch.Size([32, 2401, 200]),E_V_V.shapetorch.Size([32, 2401, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 49])
adj matrix shape is :@@## torch.Size([32, 98, 98])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 98, 1])
output的shape是: torch.Size([32, 98, 200])
##mask_batch_T shape is : torch.Size([32, 49])
##mask_batch_TT shape is : torch.Size([32, 49, 49])
E_T_T.shapetorch.Size([32, 2401, 200]),E_T_V.shapetorch.Size([32, 2401, 200]),E_V_V.shapetorch.Size([32, 2401, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 49])
adj matrix shape is :@@## torch.Size([32, 98, 98])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([32, 98, 1])
output的shape是: torch.Size([32, 98, 200])
##mask_batch_T shape is : torch.Size([32, 49])
##mask_batch_TT shape is : torch.Size([32, 49, 49])
E_T_T.shapetorch.Size([32, 2401, 200]),E_T_V.shapetorch.Size([32, 2401, 200]),E_V_V.shapetorch.Size([32, 2401, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([32, 49])
52it [00:14,  3.10it/s]##mask_batch_T shape is : torch.Size([10, 26])
##mask_batch_TT shape is : torch.Size([10, 26, 26])
E_T_T.shapetorch.Size([10, 676, 200]),E_T_V.shapetorch.Size([10, 1274, 200]),E_V_V.shapetorch.Size([10, 1274, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([10, 26])
adj matrix shape is :@@## torch.Size([10, 75, 75])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([10, 75, 1])
output的shape是: torch.Size([10, 75, 200])
##mask_batch_T shape is : torch.Size([10, 26])
##mask_batch_TT shape is : torch.Size([10, 26, 26])
E_T_T.shapetorch.Size([10, 676, 200]),E_T_V.shapetorch.Size([10, 1274, 200]),E_V_V.shapetorch.Size([10, 1274, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([10, 26])
adj matrix shape is :@@## torch.Size([10, 75, 75])
adj乘hidden.float()是m+r 200
denom的shape是: torch.Size([10, 75, 1])
output的shape是: torch.Size([10, 75, 200])
##mask_batch_T shape is : torch.Size([10, 26])
##mask_batch_TT shape is : torch.Size([10, 26, 26])
E_T_T.shapetorch.Size([10, 676, 200]),E_T_V.shapetorch.Size([10, 1274, 200]),E_V_V.shapetorch.Size([10, 1274, 200])
mask_T的形状是{}，他负责决定哪里填成负无穷 torch.Size([10, 26])
53it [00:14,  3.78it/s]53it [00:14,  3.62it/s]
20 1106 102 446
Test: Time: 14.9612, Acc: 0.2784, Loss: 0.7037, Rumor_R: 0.8139, Rumor_P: 0.2874, Rumor_F: 0.4248, Non_Rumor_R: 0.0178, Non_Rumor_P: 0.1639, Non_Rumor_F1: 0.0321
Traceback (most recent call last):
  File "train_two_record_model.py", line 301, in <module>
    main(args)
  File "train_two_record_model.py", line 182, in main
    experiment.log_metrics(train_metircs, epoch=epoch)
AttributeError: 'NoneType' object has no attribute 'log_metrics'
